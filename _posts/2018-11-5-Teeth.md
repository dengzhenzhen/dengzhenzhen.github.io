---
layout:     post
title:      FCN网络牙根分割
subtitle:   
date:       2018-11-05
author:     dengzhenzhen
header-img: 
catalog: 	 false
tags:
    - FCN网络
    - 图像分割
---

```python
from __future__ import print_function
import numpy as np
import keras
from keras.models import load_model
from keras.datasets import mnist
from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras.preprocessing.image import ImageDataGenerator
import sklearn.datasets as datasets
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import cv2
import os
import glob

IMG_SIZE = 256
LABEL_SIZE = 128
epochs = 120

training_data_path = r'training/'
num_classes = 2
model_name = 'keras_fcn_teeth.h5'
model_path_to_save = '.'
```

    Using TensorFlow backend.
    


```python
img_names = os.listdir(training_data_path)
m_tr_imgs = len(img_names)
img_buff = np.zeros((m_tr_imgs, IMG_SIZE, IMG_SIZE, 3))
label_buff = np.zeros((m_tr_imgs, LABEL_SIZE, LABEL_SIZE, 1))
for i in range(m_tr_imgs):
    img_file_path = os.path.join(training_data_path, img_names[i])
    img = cv2.imread(img_file_path)
    img = cv2.resize(img,(IMG_SIZE, IMG_SIZE))
    
    img_file_path = os.path.join(training_data_path, img_names[i])
    label = cv2.imread(img_file_path.replace('training', 'labelmap'))
    label = cv2.resize(label,(LABEL_SIZE, LABEL_SIZE))
    label = np.expand_dims(label[:,:,0], axis=-1)
    img_buff[i, :, :, :] = img/255.
    label_buff[i, :, :, :] = label/255.
    
    if np.mod(i, 20) == 1:
        print('reading images: ' + str(i) + ' / ' + str(m_tr_imgs))
```

    reading images: 1 / 100
    reading images: 21 / 100
    reading images: 41 / 100
    reading images: 61 / 100
    reading images: 81 / 100
    


```python
for i in range(3):
    plt.subplot(1,2,1)
    plt.imshow(img_buff[i, :])
    plt.subplot(1,2,2)
    plt.imshow(label_buff[i,:,:,0])
    plt.show()
```


![png](https://s1.ax1x.com/2018/11/06/iTZZ9J.png)



![png](https://s1.ax1x.com/2018/11/06/iTZANF.png)



![png](https://s1.ax1x.com/2018/11/06/iTZCn0.png)



```python
# the data, split between train and test sets
x_train, x_test, y_train, y_test = train_test_split(img_buff, label_buff, test_size=0.2)

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
```


```python
def my_simple_fcn(input_size):

    model = Sequential()

    model.add(Conv2D(16, (3, 3), padding='same',
                     input_shape=x_train.shape[1:]))
    model.add(Activation('relu'))
    model.add(Conv2D(32, (3, 3), padding='same'))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(64, (3, 3), padding='same'))
    model.add(Activation('relu'))
    model.add(Conv2D(64, (3, 3), padding='same'))
    model.add(Activation('relu'))

    model.add(Conv2D(num_classes, (3, 3), padding='same'))
    model.add(Activation('softmax'))

    # initiate RMSprop optimizer

    opt = keras.optimizers.rmsprop(lr=1e-4, decay=1e-6)

    model.compile(loss='categorical_crossentropy',
                  optimizer=opt)
    return model
```


```python
def my_functional_fcn(input_size):

    inputs = Input(input_size)
    
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    
    up4 = UpSampling2D(size=(8, 8))(pool4)
    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)
    
    up3 = UpSampling2D(size=(4, 4))(pool3)
    up3 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)
    
    up2 = UpSampling2D(size=(2, 2))(pool2)
    up2 = Conv2D(64, (3, 3), activation='relu', padding='same')(up2)
    
    up1 = pool1
    
    x = Concatenate(axis=-1)([up1, up2, up3, up4])
    
    predictions  = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)
    
    model = Model(inputs=inputs, outputs=predictions)
    
    # initiate RMSprop optimizer

    opt = keras.optimizers.rmsprop(lr=1e-4, decay=1e-6, clipnorm=.1)

    model.compile(loss='categorical_crossentropy',
                  optimizer=opt)
    return model
```


```python

model = my_simple_fcn(input_size=x_train.shape[1:])
model = my_functional_fcn(input_size=x_train.shape[1:])

from keras.utils.vis_utils import plot_model
from IPython.display import Image
plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)
Image('model.png')

```




![png](https://s1.ax1x.com/2018/11/06/iTZPBV.md.png)




```python
model = my_functional_fcn(input_size=x_train.shape[1:])
model.fit(x_train, y_train,
          epochs=120,
          batch_size=2,
          validation_data=(x_test, y_test))
          
score = model.evaluate(x_test, y_test, batch_size=2)
model.save('model.h5')
```

    WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
    Train on 80 samples, validate on 20 samples
    Epoch 1/120
    80/80 [==============================] - 54s 674ms/step - loss: 0.1766 - val_loss: 0.0374
    Epoch 2/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0445 - val_loss: 0.0343
    Epoch 3/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0394 - val_loss: 0.0300
    Epoch 4/120
    80/80 [==============================] - 42s 521ms/step - loss: 0.0350 - val_loss: 0.0238
    Epoch 5/120
    80/80 [==============================] - 42s 521ms/step - loss: 0.0344 - val_loss: 0.0336
    Epoch 6/120
    80/80 [==============================] - 42s 521ms/step - loss: 0.0284 - val_loss: 0.0440
    Epoch 7/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0276 - val_loss: 0.0167
    Epoch 8/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0250 - val_loss: 0.0162
    Epoch 9/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0244 - val_loss: 0.0144
    Epoch 10/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0227 - val_loss: 0.0179
    Epoch 11/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0212 - val_loss: 0.0131
    Epoch 12/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0183 - val_loss: 0.0168
    Epoch 13/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0169 - val_loss: 0.0133
    Epoch 14/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0158 - val_loss: 0.0131
    Epoch 15/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0154 - val_loss: 0.0118
    Epoch 16/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0143 - val_loss: 0.0106
    Epoch 17/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0138 - val_loss: 0.0106
    Epoch 18/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0128 - val_loss: 0.0111
    Epoch 19/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0119 - val_loss: 0.0098
    Epoch 20/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0117 - val_loss: 0.0092
    Epoch 21/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0119 - val_loss: 0.0089
    Epoch 22/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0107 - val_loss: 0.0102
    Epoch 23/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0105 - val_loss: 0.0081
    Epoch 24/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0098 - val_loss: 0.0078
    Epoch 25/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0097 - val_loss: 0.0091
    Epoch 26/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0093 - val_loss: 0.0077
    Epoch 27/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0091 - val_loss: 0.0078
    Epoch 28/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0092 - val_loss: 0.0082
    Epoch 29/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0086 - val_loss: 0.0085
    Epoch 30/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0082 - val_loss: 0.0066
    Epoch 31/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0079 - val_loss: 0.0071
    Epoch 32/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0079 - val_loss: 0.0063
    Epoch 33/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0073 - val_loss: 0.0064
    Epoch 34/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0072 - val_loss: 0.0063
    Epoch 35/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0072 - val_loss: 0.0057
    Epoch 36/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0069 - val_loss: 0.0056
    Epoch 37/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0067 - val_loss: 0.0075
    Epoch 38/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0066 - val_loss: 0.0069
    Epoch 39/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0063 - val_loss: 0.0054
    Epoch 40/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0065 - val_loss: 0.0056
    Epoch 41/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0062 - val_loss: 0.0056
    Epoch 42/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0059 - val_loss: 0.0059
    Epoch 43/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0059 - val_loss: 0.0050
    Epoch 44/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0058 - val_loss: 0.0049
    Epoch 45/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0056 - val_loss: 0.0047
    Epoch 46/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0055 - val_loss: 0.0061
    Epoch 47/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0055 - val_loss: 0.0065
    Epoch 48/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0054 - val_loss: 0.0049
    Epoch 49/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0051 - val_loss: 0.0050
    Epoch 50/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0052 - val_loss: 0.0055
    Epoch 51/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0050 - val_loss: 0.0045
    Epoch 52/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0050 - val_loss: 0.0044
    Epoch 53/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0048 - val_loss: 0.0042
    Epoch 54/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0047 - val_loss: 0.0055
    Epoch 55/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0050 - val_loss: 0.0041
    Epoch 56/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0046 - val_loss: 0.0043
    Epoch 57/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0049 - val_loss: 0.0044
    Epoch 58/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0045 - val_loss: 0.0042
    Epoch 59/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0044 - val_loss: 0.0041
    Epoch 60/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0043 - val_loss: 0.0040
    Epoch 61/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0042 - val_loss: 0.0039
    Epoch 62/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0042 - val_loss: 0.0047
    Epoch 63/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0040 - val_loss: 0.0051
    Epoch 64/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0040 - val_loss: 0.0043
    Epoch 65/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0041 - val_loss: 0.0038
    Epoch 66/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0039 - val_loss: 0.0042
    Epoch 67/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0039 - val_loss: 0.0041
    Epoch 68/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0038 - val_loss: 0.0039
    Epoch 69/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0037 - val_loss: 0.0039
    Epoch 70/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0038 - val_loss: 0.0038
    Epoch 71/120
    80/80 [==============================] - 41s 517ms/step - loss: 0.0036 - val_loss: 0.0045
    Epoch 72/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0036 - val_loss: 0.0045
    Epoch 73/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0037 - val_loss: 0.0037
    Epoch 74/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0034 - val_loss: 0.0039
    Epoch 75/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0034 - val_loss: 0.0036
    Epoch 76/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0033 - val_loss: 0.0039
    Epoch 77/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0034 - val_loss: 0.0042
    Epoch 78/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0032 - val_loss: 0.0036
    Epoch 79/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0032 - val_loss: 0.0045
    Epoch 80/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0032 - val_loss: 0.0035
    Epoch 81/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0031 - val_loss: 0.0035
    Epoch 82/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0032 - val_loss: 0.0036
    Epoch 83/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0029 - val_loss: 0.0036
    Epoch 84/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0031 - val_loss: 0.0034
    Epoch 85/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0030 - val_loss: 0.0035
    Epoch 86/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0028 - val_loss: 0.0039
    Epoch 87/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0029 - val_loss: 0.0046
    Epoch 88/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0029 - val_loss: 0.0035
    Epoch 89/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0028 - val_loss: 0.0039
    Epoch 90/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0027 - val_loss: 0.0034
    Epoch 91/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0027 - val_loss: 0.0068
    Epoch 92/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0028 - val_loss: 0.0033
    Epoch 93/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0026 - val_loss: 0.0039
    Epoch 94/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0027 - val_loss: 0.0035
    Epoch 95/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0026 - val_loss: 0.0034
    Epoch 96/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0025 - val_loss: 0.0034
    Epoch 97/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0026 - val_loss: 0.0042
    Epoch 98/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0024 - val_loss: 0.0039
    Epoch 99/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0024 - val_loss: 0.0046
    Epoch 100/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0024 - val_loss: 0.0050
    Epoch 101/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0024 - val_loss: 0.0043
    Epoch 102/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0022 - val_loss: 0.0039
    Epoch 103/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0024 - val_loss: 0.0034
    Epoch 104/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0022 - val_loss: 0.0035
    Epoch 105/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0023 - val_loss: 0.0033
    Epoch 106/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0022 - val_loss: 0.0042
    Epoch 107/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0021 - val_loss: 0.0034
    Epoch 108/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0022 - val_loss: 0.0035
    Epoch 109/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0021 - val_loss: 0.0051
    Epoch 110/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0021 - val_loss: 0.0033
    Epoch 111/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0020 - val_loss: 0.0061
    Epoch 112/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0021 - val_loss: 0.0041
    Epoch 113/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0020 - val_loss: 0.0034
    Epoch 114/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0021 - val_loss: 0.0036
    Epoch 115/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0019 - val_loss: 0.0043
    Epoch 116/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0021 - val_loss: 0.0038
    Epoch 117/120
    80/80 [==============================] - 42s 519ms/step - loss: 0.0018 - val_loss: 0.0036
    Epoch 118/120
    80/80 [==============================] - 41s 519ms/step - loss: 0.0019 - val_loss: 0.0037
    Epoch 119/120
    80/80 [==============================] - 42s 520ms/step - loss: 0.0018 - val_loss: 0.0041
    Epoch 120/120
    80/80 [==============================] - 41s 518ms/step - loss: 0.0018 - val_loss: 0.0035
    20/20 [==============================] - 4s 182ms/step
    


```python
model = load_model('model.h5')

# test_data_path = training_data_path
test_data_path = 'CBCT_testing/'

img_dirs = glob.glob(test_data_path+'/*.tif')
m_te_imgs = len(img_dirs)
# m_te_imgs = 5
for i in range(m_te_imgs):
    img = cv2.imread(img_dirs[i])
    img_ = cv2.resize(img,(IMG_SIZE, IMG_SIZE))
    img_ = img_/255.
    img_ = np.expand_dims(img_, axis=0)
    pred_prob_map = model.predict(img_)
    pred_cls_map = np.argmax(pred_prob_map[0,:], axis=-1)

    plt.subplot(1,3,1)
    plt.imshow(img)
    plt.subplot(1,3,2)
    plt.imshow(pred_cls_map, cmap='gray')
    plt.subplot(1,3,3)
    plt.imshow(pred_prob_map[0,:,:,-1])
    plt.show()
```


![png](https://s1.ax1x.com/2018/11/06/iTZpXq.png)



![png](https://s1.ax1x.com/2018/11/06/iTZi7T.png)



![png](https://s1.ax1x.com/2018/11/06/iTZkAU.png)



![png](https://s1.ax1x.com/2018/11/06/iTZe39.png)



![png](https://s1.ax1x.com/2018/11/06/iTZEh4.png)



```python

```


```python

```
